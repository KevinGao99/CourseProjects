{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59qfiDHHeyin"
   },
   "source": [
    "# Project 3\n",
    "The prediction of molecular properties is an important task in drug discovery. The molecules' atomic composition and arrangement can already tell us a lot about their biological behavior. Each 2D molecule can be represented as a graph, where the nodes are atoms connected by edges corresponding to chemical bonds. The prediction of molecular properties can be formulized as a graph classification task, and graph neural network is usually applied for making graph-level prediction.\n",
    "\n",
    "In this project, you need develop a model for predicting the toxicity of new molecules. This notebook provides a sample pipeline that establishes a baseline. It is expected that your methods should outperform this baseline. You are strongly encouraged to think about designing more powerful models, finetuning hyperparameters, developing better training strategies, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTCASsyypP4K"
   },
   "source": [
    "# Install package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQLM3rMTpu6r"
   },
   "source": [
    "# Some tutorials.\n",
    "\n",
    "\n",
    "\n",
    "1.   Pytorch geometric package: https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html\n",
    "2.   PyTorch Geometric for Graph-Based Molecular Property Prediction using MoleculeNet benchmark: https://medium.com/@nikopavl4/pytorch-geometric-for-graph-based-molecular-property-prediction-using-moleculenet-benchmark-41e36369d3c6\n",
    "3. Graph neural networks for graph classification. https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing\n",
    "4. Related github repository on molecular property predictions. https://github.com/yifeiwang15/MotifConv/tree/main/MCM_for_molecule_benchmarks\n",
    "\n",
    "\n",
    "## What are node and edge features in a molecule.\n",
    "\n",
    "### Node features:\n",
    "\n",
    "**Atomic number**: Number of protons in the nucleus of an atom. It’s characteristic of a chemical element and determines its place in the periodic table.\n",
    "\n",
    "**Chirality**: A molecule is chiral if it is distinguishable from its mirror image by any combination of rotations, translations, and some conformational changes. Different types of chirality exist depending on the molecule and the arrangement of the atoms.\n",
    "\n",
    "**Degree**: Number of directly-bonded neighbors of the atom.\n",
    "Formal charge: Charge assigned to an atom. It reflects the electron count associated with the atom compared to the isolated neutral atom.\n",
    "\n",
    "**Number of H**: Total number of hydrogen atoms on the atom.\n",
    "Number of radical e: Number of unpaired electrons of the atom.\n",
    "\n",
    "**Hybridization**: Atom’s hybridization.\n",
    "\n",
    "**Is aromatic**: Whether it is included in a cyclic structure with pi bonds. This type of structure tends to be very stable in comparison with other geometric arrangements of the same atoms.\n",
    "\n",
    "**Is in ring**: Whether it is included in a ring (a simple cycle of atoms and bonds in a molecule).\n",
    "\n",
    "### Edge features:\n",
    "\n",
    "**Bond type:**: Whether the bond is single, double, triple, or aromatic.\n",
    "\n",
    "**Stereo Type:** Stereo configuration of the bond.\n",
    "\n",
    "**Is conjugated**: Whether or not the bond is considered to be conjugated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0054Ib-4Vfaj"
   },
   "source": [
    "# Dataset preparation and train-valid splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "atIc86zFnj0c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wqVa56ajntas",
    "outputId": "6a4b393f-2369-4aa7-9a04-40edc8ac3bfd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 6264\n",
      "Size of validation set: 783\n",
      "Size of test set: 784\n"
     ]
    }
   ],
   "source": [
    "# Load datasets. The training and validation sets contain both molecules and their property labels. The test set only contain molecules.\n",
    "# There are 12 property tasks for prediction. Some properties labels are missing (i.e., nan). You can ignore them.\n",
    "train_dataset = torch.load(\"train_data.pt\")\n",
    "valid_dataset = torch.load(\"valid_data.pt\")\n",
    "test_dataset = torch.load(\"test_data.pt\")\n",
    "\n",
    "print(f'Size of training set: {len(train_dataset)}')\n",
    "print(f'Size of validation set: {len(valid_dataset)}')\n",
    "print(f'Size of test set: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQRRylPsVYKn",
    "outputId": "8230bbf8-db6d-4bf5-fd28-cd754afb2679",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 12], smiles='CC(O)(P(=O)(O)O)P(=O)(O)O')\n",
      "Get node feature matrix:\n",
      "tensor([[ 6,  0,  4,  5,  3,  0,  4,  0,  0],\n",
      "        [ 6,  0,  4,  5,  0,  0,  4,  0,  0],\n",
      "        [ 8,  0,  2,  5,  1,  0,  4,  0,  0],\n",
      "        [15,  0,  4,  5,  0,  0,  4,  0,  0],\n",
      "        [ 8,  0,  1,  5,  0,  0,  3,  0,  0],\n",
      "        [ 8,  0,  2,  5,  1,  0,  4,  0,  0],\n",
      "        [ 8,  0,  2,  5,  1,  0,  4,  0,  0],\n",
      "        [15,  0,  4,  5,  0,  0,  4,  0,  0],\n",
      "        [ 8,  0,  1,  5,  0,  0,  3,  0,  0],\n",
      "        [ 8,  0,  2,  5,  1,  0,  4,  0,  0],\n",
      "        [ 8,  0,  2,  5,  1,  0,  4,  0,  0]])\n",
      "torch.Size([11, 9])\n",
      "Get edge index matrix:\n",
      "tensor([[ 0,  1,  1,  1,  1,  2,  3,  3,  3,  3,  4,  5,  6,  7,  7,  7,  7,  8,\n",
      "          9, 10],\n",
      "        [ 1,  0,  2,  3,  7,  1,  1,  4,  5,  6,  3,  3,  3,  1,  8,  9, 10,  7,\n",
      "          7,  7]])\n",
      "torch.Size([2, 20])\n",
      "Get edge attribute matrix:\n",
      "tensor([[1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [2, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [2, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [2, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [2, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0]])\n",
      "torch.Size([20, 3])\n",
      "Get molecular property labels:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "# one graph example\n",
    "g = train_dataset[0]\n",
    "print(g)\n",
    "\n",
    "print(\"Get node feature matrix:\")\n",
    "print(g.x)\n",
    "print(g.x.shape) # (num_of_nodes, num_of_node_features)\n",
    "\n",
    "print(\"Get edge index matrix:\")\n",
    "print(g.edge_index)\n",
    "print(g.edge_index.shape) # (2, num_of_edges)\n",
    "\n",
    "print(\"Get edge attribute matrix:\")\n",
    "print(g.edge_attr)\n",
    "print(g.edge_attr.shape) # (num_of_edges, num_of_edge_features)\n",
    "\n",
    "print(\"Get molecular property labels:\")\n",
    "print(g.y)\n",
    "print(g.y.shape) # (1, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cilgcBXdCNS3"
   },
   "source": [
    "As we can observe, we have 11 nodes (rows) and each node has 9 features (columns). However, the features provided by Moleculenet are discrete and of type long, so we need to convert them first to continuous embeddings in order to feed them in any ML model.\n",
    "\n",
    "For example, the first column indicates the atomic number of a node, where 1 represents Hydrogen, 6 represents Carbon, 8 for Oxygen, according to periodic table of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZLIUrqobxY3",
    "outputId": "aafde21f-b0ec-4df3-99f5-8f25b2966f42",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Example of preparing data loaders.\n",
    "# You can use any batch size and see what happens in model performance.\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "batch_size=32\n",
    "train_loader = DataLoader(train_dataset * 32, batch_size=batch_size * 32, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wdzj4S9Jds3m",
    "outputId": "9d22b922-9c93-43a6-9263-1ebf2579f701",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[16916, 9], edge_index=[2, 34518], edge_attr=[34518, 3], y=[1024, 12], smiles=[1024], batch=[16916], ptr=[1025])\n"
     ]
    }
   ],
   "source": [
    "# Example of creating one mini-batch\n",
    "# See more info about mini-batch in pytorch geometric in https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc2_Mytlhn5P"
   },
   "source": [
    "# Visualization of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "BNoZJPN0ic5S",
    "outputId": "cfa92541-b0ef-4029-f4da-67d0b58ea952",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fcffc93ab30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize one 2D molecule.\n",
    "from rdkit import Chem\n",
    "Chem.MolFromSmiles(g.smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3O_MZj_TjJ7"
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0Agk424bTnmZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Atom encoder\n",
    "\n",
    "class AtomEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(AtomEncoder, self).__init__()\n",
    "\n",
    "        self.embeddings = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(9):\n",
    "            self.embeddings.append(torch.nn.Embedding(100, hidden_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for embedding in self.embeddings:\n",
    "            embedding.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        out = 0\n",
    "        for i in range(x.size(1)):\n",
    "            out += self.embeddings[i](x[:, i])\n",
    "        return out\n",
    "\n",
    "\n",
    "# A simple graph neural network model\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.emb = AtomEncoder(hidden_channels=32)\n",
    "        self.conv1 = GCNConv(hidden_channels,hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x0 , edge_index, batch_size = batch.x, batch.edge_index, batch.batch\n",
    "        x = self.emb(x0)\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # \n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Set2Set\n",
    "from torch_geometric.nn import ResGatedGraphConv\n",
    "from torch_geometric.nn import GATConv, TransformerConv\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
    "        super(Transformer, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.emb = AtomEncoder(hidden_channels=32)\n",
    "        self.conv1 = GATConv(hidden_channels,hidden_channels, edge_dim = 3)\n",
    "        self.conv2 = ResGatedGraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels, edge_dim = 3)\n",
    "        self.conv4 = ResGatedGraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "        self.bn1 = BatchNorm(hidden_channels)\n",
    "        self.bn2 = BatchNorm(hidden_channels)\n",
    "        self.pooling = Set2Set(hidden_channels, processing_steps = 4)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x0 , edge_index, batch_size, edge_attr = batch.x, batch.edge_index, batch.batch, batch.edge_attr\n",
    "        edge_attr = edge_attr.type(torch.LongTensor)\n",
    "        x = self.emb(x0)\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        #\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class res(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
    "        super(res, self).__init__()\n",
    "        self.emb = AtomEncoder(hidden_channels = 32)\n",
    "        self.conv1 = ResGatedGraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = ResGatedGraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = ResGatedGraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x0 , edge_index, batch_size, edge_attr = batch.x, batch.edge_index, batch.batch, batch.edge_attr\n",
    "        x = self.emb(x0)\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # \n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyi8ZC9YUCUS",
    "outputId": "112420f1-d6a0-4cec-b235-22f811683e12",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12])\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "model = GCN(32, 9, 12)\n",
    "\n",
    "# prediction\n",
    "out = model(batch)\n",
    "print(out.shape) #(num_of_graph, num_of_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn.conv import TransformerConv\n",
    "from torch_geometric.nn import Set2Set\n",
    "from torch_geometric.nn import BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "# Supported edge types\n",
    "SUPPORTED_EDGES = [\"SINGLE\", \"DOUBLE\", \"TRIPLE\", \"AROMATIC\"]\n",
    "\n",
    "# Supported atoms \n",
    "SUPPORTED_ATOMS = [\"C\", \"N\", \"O\", \"F\", \"P\", \"S\", \"Cl\", \"Br\", \"I\"]\n",
    "ATOMIC_NUMBERS =  [6, 7, 8, 9, 15, 16, 17, 35, 53]\n",
    "\n",
    "# Dataset (if you change this, delete the processed files to run again)\n",
    "MAX_MOLECULE_SIZE = 20  \n",
    "\n",
    "# To remove valence errors ect.\n",
    "DISABLE_RDKIT_WARNINGS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = Transformer(32, 9, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIAfufrpuKAm"
   },
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vCQE_TIoUw4x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(reduction = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6SL3fUw4VD38",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and eval function\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def train(model, device, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        y = batch.y.view(pred.shape).to(torch.float64)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        ## ignore nan targets (unlabeled) when computing training loss.\n",
    "        is_labeled = batch.y == batch.y\n",
    "        loss = criterion(pred.to(torch.float32)[is_labeled], batch.y.to(torch.float32)[is_labeled]).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "def eval(model, device, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # For every batch in test loader\n",
    "    for batch in loader:\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape))\n",
    "            y_pred.append(pred)\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "    # Compute the ROC - AUC score and store as history\n",
    "    rocauc_list = []\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        #AUC is only defined when there is at least one positive data.\n",
    "        if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == 0) > 0:\n",
    "            # ignore nan values\n",
    "            is_labeled = y_true[:,i] == y_true[:,i]\n",
    "            rocauc_list.append(roc_auc_score(y_true[is_labeled,i], y_pred[is_labeled,i]))\n",
    "\n",
    "    if len(rocauc_list) == 0:\n",
    "        raise RuntimeError('No positively labeled data available. Cannot compute ROC-AUC.')\n",
    "\n",
    "    return {'rocauc': sum(rocauc_list)/len(rocauc_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = Transformer(32, 9, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "====epoch 1\n",
      "{'Train': {'rocauc': 0.7378882820701488}, 'Validation': {'rocauc': 0.7166778056710305}}\n",
      "====epoch 2\n",
      "{'Train': {'rocauc': 0.7920720728046722}, 'Validation': {'rocauc': 0.7521601977504302}}\n",
      "====epoch 3\n",
      "{'Train': {'rocauc': 0.8141656476025493}, 'Validation': {'rocauc': 0.7596852107874685}}\n",
      "====epoch 4\n",
      "{'Train': {'rocauc': 0.826035960616129}, 'Validation': {'rocauc': 0.7654443770844525}}\n",
      "====epoch 5\n",
      "{'Train': {'rocauc': 0.8374085554456178}, 'Validation': {'rocauc': 0.7713463399480558}}\n",
      "====epoch 6\n",
      "{'Train': {'rocauc': 0.8445408642031156}, 'Validation': {'rocauc': 0.7729141651450497}}\n",
      "====epoch 7\n",
      "{'Train': {'rocauc': 0.853395542184329}, 'Validation': {'rocauc': 0.7735870203166701}}\n",
      "====epoch 8\n",
      "{'Train': {'rocauc': 0.8575854141957736}, 'Validation': {'rocauc': 0.7733086866048957}}\n",
      "====epoch 9\n",
      "{'Train': {'rocauc': 0.8621076124704108}, 'Validation': {'rocauc': 0.7740308977630036}}\n",
      "====epoch 10\n",
      "{'Train': {'rocauc': 0.8650173236760529}, 'Validation': {'rocauc': 0.7715719628321748}}\n"
     ]
    }
   ],
   "source": [
    "model2 = res(32, 9, 12)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
    "print(\"Start training...\")\n",
    "for epoch in range(1, 11):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "\n",
    "    # training\n",
    "    train(model2, device, train_loader, optimizer = optimizer)\n",
    "\n",
    "    # evaluating\n",
    "    train_acc = eval(model2, device, train_loader)\n",
    "    val_acc = eval(model2, device, val_loader)\n",
    "    print({'Train': train_acc, 'Validation': val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class singleres(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
    "        super(singleres, self).__init__()\n",
    "        self.emb = AtomEncoder(hidden_channels = 32)\n",
    "        self.conv1 = ResGatedGraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = ResGatedGraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = ResGatedGraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x0 , edge_index, batch_size, edge_attr = batch.x, batch.edge_index, batch.batch, batch.edge_attr\n",
    "        x = self.emb(x0)\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "      # \n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "====epoch 1\n",
      "{'Train': {'rocauc': 0.7044288462366683}, 'Validation': {'rocauc': 0.682887238019943}}\n",
      "====epoch 2\n",
      "{'Train': {'rocauc': 0.737167686220705}, 'Validation': {'rocauc': 0.7218072783800533}}\n",
      "====epoch 3\n",
      "{'Train': {'rocauc': 0.7613893483729725}, 'Validation': {'rocauc': 0.7416578280318445}}\n",
      "====epoch 4\n",
      "{'Train': {'rocauc': 0.7795924253976145}, 'Validation': {'rocauc': 0.7497512415451606}}\n",
      "====epoch 5\n",
      "{'Train': {'rocauc': 0.794264907838568}, 'Validation': {'rocauc': 0.7551126282051155}}\n",
      "====epoch 6\n",
      "{'Train': {'rocauc': 0.806003048982553}, 'Validation': {'rocauc': 0.7597011140504663}}\n",
      "====epoch 7\n",
      "{'Train': {'rocauc': 0.8164400217497733}, 'Validation': {'rocauc': 0.7613622944331108}}\n",
      "====epoch 8\n",
      "{'Train': {'rocauc': 0.8231512884714604}, 'Validation': {'rocauc': 0.7639033829477732}}\n",
      "====epoch 9\n",
      "{'Train': {'rocauc': 0.8281429829180075}, 'Validation': {'rocauc': 0.7652076776671414}}\n",
      "====epoch 10\n",
      "{'Train': {'rocauc': 0.8324693078571275}, 'Validation': {'rocauc': 0.7649189544259688}}\n"
     ]
    }
   ],
   "source": [
    "model3 = singleres(32, 9, 12)\n",
    "optimizer = optim.Adam(model3.parameters(), lr=0.001)\n",
    "print(\"Start training...\")\n",
    "for epoch in range(1, 11):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "\n",
    "    # training\n",
    "    train(model3, device, train_loader, optimizer = optimizer)\n",
    "\n",
    "    # evaluating\n",
    "    train_acc = eval(model3, device, train_loader)\n",
    "    val_acc = eval(model3, device, val_loader)\n",
    "    print({'Train': train_acc, 'Validation': val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYM7x48bZugM",
    "outputId": "39bdfa93-9de4-4510-e911-122dc9eb1437",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "====epoch 1\n",
      "{'Train': {'rocauc': 0.7900561075866954}, 'Validation': {'rocauc': 0.7497023146404421}}\n",
      "====epoch 2\n",
      "{'Train': {'rocauc': 0.845288720372695}, 'Validation': {'rocauc': 0.7587628695691794}}\n",
      "====epoch 3\n",
      "{'Train': {'rocauc': 0.8610520293746199}, 'Validation': {'rocauc': 0.7541338192069614}}\n",
      "====epoch 4\n",
      "{'Train': {'rocauc': 0.8723723728796894}, 'Validation': {'rocauc': 0.7534637054472589}}\n",
      "====epoch 5\n",
      "{'Train': {'rocauc': 0.8724715602140664}, 'Validation': {'rocauc': 0.7451533511710684}}\n",
      "====epoch 6\n",
      "{'Train': {'rocauc': 0.8867936803823948}, 'Validation': {'rocauc': 0.7527612276346597}}\n",
      "====epoch 7\n",
      "{'Train': {'rocauc': 0.8909183509581938}, 'Validation': {'rocauc': 0.7522644893570645}}\n",
      "====epoch 8\n",
      "{'Train': {'rocauc': 0.8940410042586574}, 'Validation': {'rocauc': 0.7510325929475354}}\n",
      "====epoch 9\n",
      "{'Train': {'rocauc': 0.8967917621967386}, 'Validation': {'rocauc': 0.7511412659536519}}\n",
      "====epoch 10\n",
      "{'Train': {'rocauc': 0.9017894603429729}, 'Validation': {'rocauc': 0.753534537959287}}\n",
      "====epoch 11\n",
      "{'Train': {'rocauc': 0.9070625546568721}, 'Validation': {'rocauc': 0.7479989743365487}}\n",
      "====epoch 12\n",
      "{'Train': {'rocauc': 0.9072349395617127}, 'Validation': {'rocauc': 0.7480419783503534}}\n",
      "====epoch 13\n",
      "{'Train': {'rocauc': 0.9127621672769174}, 'Validation': {'rocauc': 0.7522771178783866}}\n",
      "====epoch 14\n",
      "{'Train': {'rocauc': 0.9132080480535866}, 'Validation': {'rocauc': 0.7536345562437635}}\n",
      "====epoch 15\n",
      "{'Train': {'rocauc': 0.9159520179355475}, 'Validation': {'rocauc': 0.7532544682949306}}\n",
      "====epoch 16\n",
      "{'Train': {'rocauc': 0.9169365436530712}, 'Validation': {'rocauc': 0.7589244784521946}}\n",
      "====epoch 17\n",
      "{'Train': {'rocauc': 0.9202579467224995}, 'Validation': {'rocauc': 0.7511481072454598}}\n",
      "====epoch 18\n",
      "{'Train': {'rocauc': 0.9227511096874489}, 'Validation': {'rocauc': 0.7520324196852998}}\n",
      "====epoch 19\n",
      "{'Train': {'rocauc': 0.9230341301185551}, 'Validation': {'rocauc': 0.7548749220538057}}\n",
      "====epoch 20\n",
      "{'Train': {'rocauc': 0.9261801784961485}, 'Validation': {'rocauc': 0.7614446664145226}}\n",
      "====epoch 21\n",
      "{'Train': {'rocauc': 0.9291557437696544}, 'Validation': {'rocauc': 0.752483950902556}}\n",
      "====epoch 22\n",
      "{'Train': {'rocauc': 0.9300241423708813}, 'Validation': {'rocauc': 0.7549459251135654}}\n",
      "====epoch 23\n",
      "{'Train': {'rocauc': 0.9315554112014236}, 'Validation': {'rocauc': 0.7571750605004882}}\n",
      "====epoch 24\n",
      "{'Train': {'rocauc': 0.9334768176981084}, 'Validation': {'rocauc': 0.7599698910546686}}\n",
      "====epoch 25\n",
      "{'Train': {'rocauc': 0.9340460944524535}, 'Validation': {'rocauc': 0.7516659715566623}}\n",
      "====epoch 26\n",
      "{'Train': {'rocauc': 0.9366431675537149}, 'Validation': {'rocauc': 0.7591550426229731}}\n",
      "====epoch 27\n",
      "{'Train': {'rocauc': 0.9388750054845065}, 'Validation': {'rocauc': 0.7515143099578081}}\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "print(\"Start training...\")\n",
    "for epoch in range(1, 28):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "\n",
    "    # training\n",
    "    train(model1, device, train_loader, optimizer = optimizer)\n",
    "\n",
    "    # evaluating\n",
    "    train_acc = eval(model1, device, train_loader)\n",
    "    val_acc = eval(model1, device, val_loader)\n",
    "    print({'Train': train_acc, 'Validation': val_acc})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch0 = next(iter(test_loader))\n",
    "out= model2(batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2182, -3.6797, -3.9013, -3.2075, -1.8235, -3.9866, -5.2993, -2.5020,\n",
       "         -5.2670, -4.4865, -3.1108, -3.4061],\n",
       "        [-2.7026, -3.3673, -2.7314, -3.1737, -1.5764, -2.6934, -3.4927, -1.7101,\n",
       "         -3.4484, -2.9163, -2.5153, -3.2494],\n",
       "        [-5.0103, -6.4391, -4.6231, -4.6804, -2.3218, -4.6273, -6.1128, -2.8319,\n",
       "         -6.4189, -4.7851, -3.7752, -5.3448],\n",
       "        [-2.0905, -2.3276, -1.2543, -1.9478, -1.5168, -2.1424, -2.2299, -0.7386,\n",
       "         -2.1566, -1.9183, -1.2547, -1.6281],\n",
       "        [-3.0705, -3.6202, -2.5693, -2.5874, -1.1168, -1.9073, -3.4724, -1.4559,\n",
       "         -3.7561, -2.7106, -0.8673, -3.1930],\n",
       "        [-3.5801, -4.4674, -2.3584, -3.4113, -2.1112, -3.9188, -4.2333, -1.8810,\n",
       "         -3.9138, -3.4818, -3.0669, -3.4182],\n",
       "        [-1.0127, -0.6390,  2.6492,  0.9510,  0.4442,  0.9834, -0.0660,  1.2258,\n",
       "          0.7543,  0.4470,  3.4643,  0.8639],\n",
       "        [-2.5356, -3.2336,  0.0631, -1.5058, -1.2824, -2.3074, -2.6060, -0.6976,\n",
       "         -2.0378, -1.7859,  0.0178, -1.5867],\n",
       "        [-3.6991, -4.5298, -2.5409, -3.3790, -1.8159, -3.4710, -4.1377, -1.8112,\n",
       "         -3.9309, -3.2831, -2.6419, -3.5427],\n",
       "        [-3.1811, -3.6576, -1.4983, -3.0918, -1.8793, -3.3318, -3.2935, -1.0959,\n",
       "         -2.6293, -2.6966, -2.6899, -2.4195],\n",
       "        [-4.0351, -5.0647, -2.4003, -3.4548, -2.0141, -3.9271, -4.5575, -1.8738,\n",
       "         -4.2990, -3.6156, -2.6800, -3.5396],\n",
       "        [-3.2967, -4.0789, -1.9167, -3.2065, -1.7317, -3.2764, -3.7870, -1.6344,\n",
       "         -3.3522, -3.0837, -2.5637, -3.0969],\n",
       "        [-3.1212, -4.0105, -3.4445, -2.7217, -1.4790, -2.6715, -3.9694, -1.7100,\n",
       "         -4.5521, -3.2063, -1.7445, -3.3641],\n",
       "        [-3.6712, -4.4649, -2.2222, -3.1299, -2.0014, -3.5931, -4.1033, -1.4691,\n",
       "         -3.8366, -3.0556, -2.3951, -3.1528],\n",
       "        [-2.8534, -3.0640, -0.7715, -1.6586, -0.8852, -1.5367, -2.4888, -0.5265,\n",
       "         -2.0287, -1.6187, -0.2255, -1.7983],\n",
       "        [-2.8305, -3.1249, -0.8841, -1.0376, -1.2228, -1.9001, -2.4217, -0.4596,\n",
       "         -2.2228, -1.3386,  0.0877, -1.5833],\n",
       "        [-2.4568, -1.4000,  0.7479,  0.1506, -0.9241, -0.0564, -0.0569,  1.6542,\n",
       "         -0.2591,  0.6820,  2.5167,  0.5957],\n",
       "        [-2.1677, -2.8394, -1.7957, -2.4113, -1.1679, -2.2830, -3.5540, -1.3114,\n",
       "         -3.2512, -2.8312, -1.3423, -2.4972],\n",
       "        [-4.3802, -5.2493, -1.7913, -2.6356, -1.9319, -3.3213, -4.0401, -1.6100,\n",
       "         -3.8955, -2.7270, -1.2725, -3.3652],\n",
       "        [-4.3404, -6.0230, -2.6219, -3.7562, -2.4702, -4.8510, -5.0320, -2.4491,\n",
       "         -5.0165, -4.0293, -3.0160, -4.0609],\n",
       "        [-4.9335, -7.1170, -4.3569, -5.2692, -3.0690, -6.5948, -7.0130, -3.6913,\n",
       "         -6.7574, -5.8297, -5.3655, -5.5030],\n",
       "        [-3.5914, -4.3721, -3.3589, -4.4438, -2.1745, -4.0349, -4.6506, -2.2120,\n",
       "         -4.5434, -4.1237, -3.7938, -4.2257],\n",
       "        [-3.3001, -4.3984, -3.2045, -3.6114, -1.7121, -3.6963, -5.0294, -2.0758,\n",
       "         -4.9674, -4.2822, -2.6307, -3.6187],\n",
       "        [-3.5486, -3.9668,  0.0712, -2.2451, -2.0444, -3.9223, -3.6803, -1.0711,\n",
       "         -2.0462, -2.3799, -2.1993, -2.0231],\n",
       "        [-5.1662, -6.9942, -3.1399, -4.7175, -2.8293, -5.8040, -6.0885, -3.0624,\n",
       "         -5.7314, -5.0146, -4.1105, -4.9258],\n",
       "        [-4.0187, -4.8421, -2.0343, -3.5077, -1.9873, -3.7241, -4.3050, -1.7645,\n",
       "         -4.0090, -3.5526, -2.6490, -3.4642],\n",
       "        [-3.5593, -4.0509, -1.6839, -2.3699, -1.8217, -3.2367, -3.7976, -1.2503,\n",
       "         -3.3981, -2.7084, -1.8979, -2.7689],\n",
       "        [-3.9419, -4.9246, -1.9658, -3.3011, -2.0382, -3.9747, -4.2077, -1.7559,\n",
       "         -3.7455, -3.3704, -2.6375, -3.1468],\n",
       "        [-2.8341, -3.2187, -3.1362, -1.9409, -1.4034, -2.1017, -3.4724, -0.8413,\n",
       "         -3.9593, -2.1400, -0.6032, -2.4421],\n",
       "        [-2.4123, -3.0814, -3.0453, -3.2059, -1.5913, -3.0212, -3.7353, -1.8476,\n",
       "         -3.6064, -3.4435, -2.9889, -2.9054],\n",
       "        [-3.7294, -4.5933, -3.5211, -3.2780, -1.3274, -2.5746, -4.4072, -2.0998,\n",
       "         -4.8101, -3.4025, -1.7377, -4.1397],\n",
       "        [-2.9958, -3.0327, -0.3239, -1.8367, -1.6209, -2.6023, -2.6013, -0.7045,\n",
       "         -1.5683, -1.6759, -1.5734, -1.7693]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out1 = out.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.218249  , -3.679664  , -3.9013472 , -3.207549  , -1.8234892 ,\n",
       "        -3.986563  , -5.29929   , -2.5019872 , -5.2669864 , -4.4864764 ,\n",
       "        -3.1108024 , -3.4060636 ],\n",
       "       [-2.7025828 , -3.3673499 , -2.7313542 , -3.173658  , -1.5764413 ,\n",
       "        -2.6933959 , -3.4926717 , -1.710114  , -3.4483726 , -2.9162884 ,\n",
       "        -2.515339  , -3.2493844 ],\n",
       "       [-5.0102777 , -6.43909   , -4.623052  , -4.6803565 , -2.3218474 ,\n",
       "        -4.6272984 , -6.1128497 , -2.831858  , -6.4189057 , -4.7851086 ,\n",
       "        -3.775233  , -5.3448014 ],\n",
       "       [-2.0904596 , -2.3275793 , -1.2543137 , -1.9477594 , -1.5167558 ,\n",
       "        -2.142404  , -2.2299414 , -0.7385742 , -2.1566198 , -1.9183242 ,\n",
       "        -1.2546685 , -1.6281484 ],\n",
       "       [-3.0705056 , -3.6201978 , -2.569274  , -2.5873613 , -1.1167762 ,\n",
       "        -1.9073344 , -3.4723535 , -1.4559431 , -3.7560608 , -2.7105744 ,\n",
       "        -0.8672996 , -3.1930127 ],\n",
       "       [-3.5801103 , -4.4673886 , -2.3583837 , -3.4113202 , -2.111231  ,\n",
       "        -3.9188316 , -4.2333364 , -1.8810275 , -3.9138372 , -3.4817839 ,\n",
       "        -3.0668628 , -3.4182372 ],\n",
       "       [-1.0126867 , -0.63904047,  2.6492429 ,  0.9509548 ,  0.44415534,\n",
       "         0.9834484 , -0.06603116,  1.2257835 ,  0.75432366,  0.44702685,\n",
       "         3.4642994 ,  0.8638942 ],\n",
       "       [-2.5355728 , -3.2336082 ,  0.06310111, -1.5057838 , -1.2824192 ,\n",
       "        -2.307362  , -2.605962  , -0.6976121 , -2.0377629 , -1.7858634 ,\n",
       "         0.01782486, -1.5866808 ],\n",
       "       [-3.6990864 , -4.529833  , -2.5409064 , -3.3790398 , -1.8159492 ,\n",
       "        -3.470974  , -4.1377306 , -1.8112092 , -3.9309447 , -3.2831087 ,\n",
       "        -2.6419013 , -3.5426583 ],\n",
       "       [-3.1811097 , -3.657607  , -1.4983045 , -3.0917556 , -1.8793167 ,\n",
       "        -3.3317897 , -3.2935371 , -1.0958968 , -2.6292803 , -2.6966023 ,\n",
       "        -2.6898797 , -2.4194927 ],\n",
       "       [-4.035142  , -5.0646763 , -2.4002771 , -3.454826  , -2.0140557 ,\n",
       "        -3.92705   , -4.5574956 , -1.8737681 , -4.2990494 , -3.6155608 ,\n",
       "        -2.679974  , -3.539566  ],\n",
       "       [-3.296736  , -4.0788646 , -1.9166561 , -3.206451  , -1.7316936 ,\n",
       "        -3.276421  , -3.7869725 , -1.6344385 , -3.3521574 , -3.083699  ,\n",
       "        -2.5636802 , -3.096898  ],\n",
       "       [-3.1211998 , -4.0104976 , -3.4445262 , -2.721739  , -1.4790357 ,\n",
       "        -2.67153   , -3.9694057 , -1.7100419 , -4.552057  , -3.206263  ,\n",
       "        -1.7444773 , -3.3640642 ],\n",
       "       [-3.6711547 , -4.4649153 , -2.2221615 , -3.129917  , -2.0014188 ,\n",
       "        -3.5931227 , -4.1033196 , -1.4690562 , -3.8366401 , -3.0556304 ,\n",
       "        -2.3950808 , -3.1528044 ],\n",
       "       [-2.8533752 , -3.0640113 , -0.77146083, -1.6585689 , -0.88517404,\n",
       "        -1.5367404 , -2.488802  , -0.52650464, -2.0286584 , -1.6187128 ,\n",
       "        -0.2255352 , -1.7983173 ],\n",
       "       [-2.8305078 , -3.1249151 , -0.88408244, -1.0375841 , -1.2228289 ,\n",
       "        -1.9001365 , -2.421748  , -0.45957056, -2.2228138 , -1.3386033 ,\n",
       "         0.08770946, -1.5832704 ],\n",
       "       [-2.4568388 , -1.3999536 ,  0.74791634,  0.1506243 , -0.9241471 ,\n",
       "        -0.05644938, -0.0569095 ,  1.6542459 , -0.2590962 ,  0.6820352 ,\n",
       "         2.5167487 ,  0.59565216],\n",
       "       [-2.167705  , -2.83939   , -1.7957107 , -2.4112537 , -1.1679344 ,\n",
       "        -2.2830226 , -3.5539966 , -1.3113999 , -3.25124   , -2.8312378 ,\n",
       "        -1.3423128 , -2.497192  ],\n",
       "       [-4.3801584 , -5.2493196 , -1.7912529 , -2.6356475 , -1.931893  ,\n",
       "        -3.321254  , -4.040149  , -1.6099532 , -3.8955092 , -2.7270494 ,\n",
       "        -1.2724664 , -3.365193  ],\n",
       "       [-4.340399  , -6.022958  , -2.6218975 , -3.7561991 , -2.4701962 ,\n",
       "        -4.851038  , -5.0319963 , -2.4491441 , -5.0165286 , -4.0293283 ,\n",
       "        -3.01601   , -4.0609255 ],\n",
       "       [-4.933484  , -7.117015  , -4.3568764 , -5.2691593 , -3.069001  ,\n",
       "        -6.5947657 , -7.012961  , -3.6913376 , -6.757418  , -5.8297167 ,\n",
       "        -5.365521  , -5.5029936 ],\n",
       "       [-3.5914054 , -4.3721256 , -3.3588734 , -4.443783  , -2.1745405 ,\n",
       "        -4.034902  , -4.6505623 , -2.2120116 , -4.543385  , -4.123658  ,\n",
       "        -3.7938251 , -4.225728  ],\n",
       "       [-3.300083  , -4.398368  , -3.2045045 , -3.6114159 , -1.7120719 ,\n",
       "        -3.6962986 , -5.029359  , -2.0758314 , -4.9673953 , -4.2821727 ,\n",
       "        -2.63074   , -3.6186981 ],\n",
       "       [-3.5486486 , -3.9667718 ,  0.07119539, -2.245084  , -2.0444083 ,\n",
       "        -3.9223197 , -3.6802526 , -1.0710841 , -2.0462286 , -2.3798778 ,\n",
       "        -2.199342  , -2.023096  ],\n",
       "       [-5.166213  , -6.9941845 , -3.1398559 , -4.7174845 , -2.8293183 ,\n",
       "        -5.80398   , -6.0885205 , -3.0623949 , -5.7313604 , -5.014585  ,\n",
       "        -4.1104684 , -4.9258323 ],\n",
       "       [-4.0187488 , -4.8420734 , -2.0343497 , -3.5077238 , -1.987268  ,\n",
       "        -3.7241387 , -4.3050146 , -1.764474  , -4.008997  , -3.5525777 ,\n",
       "        -2.6489828 , -3.464178  ],\n",
       "       [-3.5593302 , -4.050937  , -1.6839275 , -2.3698542 , -1.8216538 ,\n",
       "        -3.2367458 , -3.7975576 , -1.2503145 , -3.398084  , -2.7083738 ,\n",
       "        -1.8979192 , -2.768939  ],\n",
       "       [-3.9419477 , -4.924622  , -1.9658225 , -3.3010714 , -2.0381823 ,\n",
       "        -3.9746935 , -4.2076697 , -1.7559171 , -3.7454762 , -3.370387  ,\n",
       "        -2.6375456 , -3.1467915 ],\n",
       "       [-2.8341184 , -3.2186918 , -3.1362019 , -1.9409338 , -1.4033599 ,\n",
       "        -2.1017313 , -3.4723701 , -0.84127873, -3.9592633 , -2.1399708 ,\n",
       "        -0.6032011 , -2.4420543 ],\n",
       "       [-2.4123466 , -3.081399  , -3.0453231 , -3.2058506 , -1.5913041 ,\n",
       "        -3.0212257 , -3.7353363 , -1.8476274 , -3.6063824 , -3.4434545 ,\n",
       "        -2.988918  , -2.9054136 ],\n",
       "       [-3.7294028 , -4.593295  , -3.5210848 , -3.2780073 , -1.3273976 ,\n",
       "        -2.574556  , -4.40719   , -2.0998087 , -4.810055  , -3.4024947 ,\n",
       "        -1.7377431 , -4.139673  ],\n",
       "       [-2.9957998 , -3.0327375 , -0.3238607 , -1.8367344 , -1.6208692 ,\n",
       "        -2.602252  , -2.601269  , -0.7044691 , -1.5683362 , -1.6759427 ,\n",
       "        -1.5734098 , -1.7693293 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(out1)\n",
    "df.to_csv('out.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
